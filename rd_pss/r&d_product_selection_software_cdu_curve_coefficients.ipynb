{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksachtleben/AFSSH/blob/main/rd_pss/r%26d_product_selection_software_cdu_curve_coefficients.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoUT0JFCOeZ6"
      },
      "outputs": [],
      "source": [
        "!pip install apache-beam[gcp,interactive,dataframe]\n",
        "!pip install pandas\n",
        "!pip install gcsfs\n",
        "!pip install decimal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nye5b97WOm2S",
        "outputId": "cdb1b31d-c959-42b7-f2ef-6a2050b1edd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authenticated\n"
          ]
        }
      ],
      "source": [
        "import apache_beam as beam\n",
        "from apache_beam.options.pipeline_options import PipelineOptions\n",
        "from apache_beam.runners import DataflowRunner\n",
        "from apache_beam.runners.interactive.interactive_runner import InteractiveRunner\n",
        "from decimal import Decimal\n",
        "import apache_beam.runners.interactive.interactive_beam as ib\n",
        "import logging\n",
        "import datetime\n",
        "import re\n",
        "\n",
        "import os\n",
        "import json\n",
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Google Auth\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')\n",
        "\n",
        "# GCP Project\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"]= 'nidec-ga'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "04JOPjZCP71Q"
      },
      "outputs": [],
      "source": [
        "def select_columns(row, columns):\n",
        "    return {column: row[column] for column in columns if column in row}\n",
        "\n",
        "\n",
        "class DropColumnsTechnical(beam.DoFn):\n",
        "    def __init__(self, cols_to_drop):\n",
        "        self.cols_to_drop = cols_to_drop\n",
        "\n",
        "    def process(self, element):\n",
        "        for col in self.cols_to_drop:\n",
        "            element.pop(col, None)\n",
        "        yield element\n",
        "\n",
        "\n",
        "class ConvertColumnToLower(beam.DoFn):\n",
        "    def __init__(self, column_name):\n",
        "        self.column_name = column_name\n",
        "\n",
        "    def process(self, element):\n",
        "        for column in self.column_name:\n",
        "            if column in element and isinstance(element[column], str):\n",
        "              element[column] = element[column].lower()\n",
        "\n",
        "        yield element\n",
        "\n",
        "\n",
        "class ReplacePatternsStartFn(beam.DoFn):\n",
        "    def __init__(self, columns, pattern, replacement):\n",
        "        self.columns = columns\n",
        "        self.pattern = pattern\n",
        "        self.replacement = replacement\n",
        "\n",
        "    def process(self, element):\n",
        "        import re\n",
        "        for column in self.columns:\n",
        "            if column in element and re.match(self.pattern, element[column]):\n",
        "                element[column] = re.sub(self.pattern, self.replacement, element[column])\n",
        "        yield element\n",
        "\n",
        "\n",
        "class ColumnsToStringConverter(beam.DoFn):\n",
        "    def __init__(self, columns_to_string):\n",
        "        self.columns_to_string = columns_to_string\n",
        "\n",
        "    def process(self, element):\n",
        "        for column in self.columns_to_string:\n",
        "           if column in element and isinstance(element[column], (int, float)):\n",
        "              try:\n",
        "                  element[column] = str(element[column])\n",
        "              except ValueError:\n",
        "                pass\n",
        "        yield element\n",
        "\n",
        "class ColumnsToFloatConverter(beam.DoFn):\n",
        "    def __init__(self, columns_to_float):\n",
        "        self.columns_to_float = columns_to_float\n",
        "\n",
        "    def process(self, element):\n",
        "        for column in self.columns_to_float:\n",
        "            if column in element and isinstance(element[column], str):\n",
        "                try:\n",
        "                  element[column] = float(element[column])\n",
        "                except ValueError:\n",
        "                  pass\n",
        "        yield element\n",
        "\n",
        "class ColumnsToIntegerConverter(beam.DoFn):\n",
        "    def __init__(self, columns_to_integer):\n",
        "        self.columns_to_integer = columns_to_integer\n",
        "\n",
        "    def process(self, element):\n",
        "        for column in self.columns_to_integer:\n",
        "            if column in element and isinstance(element[column], (str, float)):\n",
        "                try:\n",
        "                  if element[column] == \"\":\n",
        "                    element[column] = 0\n",
        "                  else:\n",
        "                    element[column] = int(element[column])\n",
        "                except ValueError:\n",
        "                  pass\n",
        "        yield element\n",
        "\n",
        "class RenameColumns(beam.DoFn):\n",
        "    def __init__(self, column_mapping):\n",
        "        self.column_mapping = column_mapping\n",
        "\n",
        "    def process(self, element):\n",
        "        new_element = {self.column_mapping.get(k, k): v for k, v in element.items()}\n",
        "        yield new_element\n",
        "\n",
        "\n",
        "class ReplaceValues(beam.DoFn):\n",
        "    def __init__(self, replacements):\n",
        "        self.replacements = replacements\n",
        "\n",
        "    def process(self, element):\n",
        "        for column, current_value, replacement  in self.replacements:\n",
        "            if column in element:\n",
        "                if isinstance(element[column], str) and current_value == element[column]:\n",
        "                  element[column] = replacement\n",
        "        yield element\n",
        "\n",
        "\n",
        "\n",
        "class HandleNaN(beam.DoFn):\n",
        "    \"\"\"\n",
        "    Treatment of NaN values ​​in the column\n",
        "    \"\"\"\n",
        "    def process(self, element):\n",
        "        import math\n",
        "        for key, value in element.items():\n",
        "            if isinstance(value, list):\n",
        "                # Replace nan in lists\n",
        "                element[key] = [\"\" if isinstance(item, float) and math.isnan(item) else item for item in value]\n",
        "            elif value is None or (isinstance(value, float) and math.isnan(value)):\n",
        "                # Replace single nan values\n",
        "                element[key] = ''\n",
        "\n",
        "        yield element\n",
        "\n",
        "\n",
        "class TypeAnalyzer(beam.DoFn):\n",
        "    \"\"\"\n",
        "    For each columns print the type, only one row\n",
        "    \"\"\"\n",
        "    def process(self, element):\n",
        "        global first_row_processed\n",
        "\n",
        "        if not first_row_processed:\n",
        "        # for each element in PCollection\n",
        "          for column, value in element.items():\n",
        "              # Print the name of column and type\n",
        "              print(f'Column: {column}, Type: {type(value).__name__}')\n",
        "          first_row_processed = True\n",
        "        # Emite o elemento inalterado\n",
        "        yield element\n",
        "\n",
        "\n",
        "class FilterMissingValuesDoFn(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        # Columns to check for missing values\n",
        "        columns_to_check = [\n",
        "            'Catalog Availability'\n",
        "        ]\n",
        "\n",
        "        # Check if any specified column has a missing value\n",
        "        if all(col in element for col in columns_to_check):\n",
        "            yield element\n",
        "\n",
        "\n",
        "class DeriveColumn(beam.DoFn):\n",
        "    def __init__(self, source_column, target_column):\n",
        "        self.source_column = source_column\n",
        "        self.target_column = target_column\n",
        "\n",
        "    def process(self, element):\n",
        "        element[self.target_column] = element[self.source_column]\n",
        "        yield element\n",
        "\n",
        "\n",
        "class TransformColumnApplication(beam.DoFn):\n",
        "    def process(self, element):\n",
        "\n",
        "        col_value = element['Application']\n",
        "        result = col_value\n",
        "\n",
        "        if col_value == 'L/MBP':\n",
        "            result = 'LBP'\n",
        "        elif col_value == 'M/HBP':\n",
        "            result = 'MBP'\n",
        "\n",
        "        element['Application'] = result\n",
        "        yield element\n",
        "\n",
        "\n",
        "class UniqueValueForNewColum(beam.DoFn):\n",
        "    def __init__(self, new_column, value_column):\n",
        "      self.new_column = new_column\n",
        "      self.value_column = value_column\n",
        "\n",
        "    def process(self, element):\n",
        "        element[self.new_column] = self.value_column\n",
        "        yield element\n",
        "\n",
        "\n",
        "class CustomTransform(beam.DoFn):\n",
        "    def process(self, element):\n",
        "\n",
        "        cc_unit = element['Units']\n",
        "        for i, col_suffix in enumerate('ABCDEFGHIJ'):\n",
        "            col_name = f'CC_{col_suffix}'\n",
        "            if cc_unit == 'w' or cc_unit == 'W':\n",
        "                element[col_name] = element[col_name]\n",
        "            elif cc_unit == 'kcal/h':\n",
        "                element[col_name] = element[col_name] * 1.163\n",
        "            elif cc_unit == 'btu/h':\n",
        "                element[col_name] = element[col_name] * 0.293071\n",
        "            else:\n",
        "                pass\n",
        "        yield element\n",
        "\n",
        "\n",
        "class ConvertToStringEcodesign(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        # Converte o valor 'YES' para string\n",
        "        element['ECODESIGN'] = str(element['ECODESIGN']) if element['ECODESIGN'] is not None else None\n",
        "        yield element"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QgSY2lwI5NEn"
      },
      "outputs": [],
      "source": [
        "class LeftJoinFn(beam.DoFn):\n",
        "    def __init__(self, columns_to_include=None):\n",
        "        # Store the columns from TABELA2 to include in the output, default to None\n",
        "        self.columns_to_include = columns_to_include\n",
        "\n",
        "    def process(self, element):\n",
        "        key, grouped_values = element\n",
        "        tabela1_values = grouped_values['TABELA1']\n",
        "        tabela2_values = grouped_values['TABELA2']\n",
        "\n",
        "        for tabela1 in tabela1_values:\n",
        "            tabela1_value = tabela1[1]  # Unpack the tuple, assuming the record is the second element\n",
        "\n",
        "            if tabela2_values:\n",
        "                for tabela2 in tabela2_values:\n",
        "                    tabela2_value = tabela2[1]\n",
        "\n",
        "                    # Filter the columns of tabela2_value if columns_to_include is provided\n",
        "                    if self.columns_to_include is not None:\n",
        "                        filtered_tabela2_value = {k: v for k, v in tabela2_value.items() if k in self.columns_to_include}\n",
        "                    else:\n",
        "                        filtered_tabela2_value = tabela2_value\n",
        "\n",
        "                    yield {**tabela1_value, **filtered_tabela2_value}\n",
        "            else:\n",
        "                yield tabela1_value\n",
        "\n",
        "\n",
        "class KeyByComposite(beam.DoFn):\n",
        "    def __init__(self, key_columns):\n",
        "        self.key_columns = key_columns\n",
        "\n",
        "    def process(self, element):\n",
        "        composite_key = {k:element[k] for k in self.key_columns if k in element}\n",
        "        grouped_data = {k:element[k] for k in element}\n",
        "        yield (composite_key, grouped_data)\n",
        "\n",
        "\n",
        "class CreateKeyDoFn(beam.DoFn):\n",
        "    def __init__(self, key_columns):\n",
        "        self.key_columns = key_columns\n",
        "\n",
        "    def process(self, element):\n",
        "        # Assuming element is a tuple and the dictionary is the first item in the tuple\n",
        "        dictionary = element[0]\n",
        "        key = tuple(dictionary[k] for k in self.key_columns)\n",
        "        yield (key, element)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "F6Q3WCqG6gcu"
      },
      "outputs": [],
      "source": [
        "class DeriveRatedCapacity(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        try:\n",
        "            tevap = float(element.get('Tevap', 0))\n",
        "            tamb = float(element.get('Tamb', 0))\n",
        "\n",
        "            #Create a caractere with ASCII\n",
        "            coeffs = [float(element.get(f'CC_{chr(65 + i)}', 0)) for i in range(10)]\n",
        "\n",
        "            rated_capacity = (coeffs[0] +\n",
        "                             coeffs[1] * tevap +\n",
        "                             coeffs[2] * tamb +\n",
        "                             coeffs[3] * tevap * tamb +\n",
        "                             coeffs[4] * tevap**2 +\n",
        "                             coeffs[5] * tamb**2 +\n",
        "                             coeffs[6] * tamb * tevap**2 +\n",
        "                             coeffs[7] * tevap * tamb**2 +\n",
        "                             coeffs[8] * tevap**3 +\n",
        "                             coeffs[9] * tamb**3)\n",
        "\n",
        "            element['RATED_CAPACITY'] = float(rated_capacity)\n",
        "            yield element\n",
        "\n",
        "        except Exception as e:\n",
        "\n",
        "            element['RATED_CAPACITY'] =  0.0\n",
        "            yield element\n",
        "\n",
        "\n",
        "class DeriveRatedPower(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        try:\n",
        "            tevap = float(element.get('Tevap', 0))\n",
        "            tamb = float(element.get('Tamb', 0))\n",
        "\n",
        "            #Create a caractere with ASCII\n",
        "            coeffs = [float(element.get(f'CON_{chr(65 + i)}', 0)) for i in range(10)]\n",
        "\n",
        "            rated_power = (coeffs[0] +\n",
        "                             coeffs[1] * tevap +\n",
        "                             coeffs[2] * tamb +\n",
        "                             coeffs[3] * tevap * tamb +\n",
        "                             coeffs[4] * tevap**2 +\n",
        "                             coeffs[5] * tamb**2 +\n",
        "                             coeffs[6] * tamb * tevap**2 +\n",
        "                             coeffs[7] * tevap * tamb**2 +\n",
        "                             coeffs[8] * tevap**3 +\n",
        "                             coeffs[9] * tamb**3)\n",
        "\n",
        "            element['RATED_POWER'] = float(rated_power)\n",
        "            yield element\n",
        "\n",
        "        except Exception as e:\n",
        "\n",
        "            element['RATED_POWER'] =  0.0\n",
        "            yield element\n",
        "\n",
        "\n",
        "class DeriveRatedCurrent(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        try:\n",
        "            tevap = float(element.get('Tevap', 0))\n",
        "            tamb = float(element.get('Tamb', 0))\n",
        "\n",
        "            #Create a caractere with ASCII\n",
        "            coeffs = [float(element.get(f'CURR_{chr(65 + i)}', 0)) for i in range(10)]\n",
        "\n",
        "            rated_current = (coeffs[0] +\n",
        "                             coeffs[1] * tevap +\n",
        "                             coeffs[2] * tamb +\n",
        "                             coeffs[3] * tevap * tamb +\n",
        "                             coeffs[4] * tevap**2 +\n",
        "                             coeffs[5] * tamb**2 +\n",
        "                             coeffs[6] * tamb * tevap**2 +\n",
        "                             coeffs[7] * tevap * tamb**2 +\n",
        "                             coeffs[8] * tevap**3 +\n",
        "                             coeffs[9] * tamb**3)\n",
        "\n",
        "            element['RATED_CURRENT'] = float(rated_current)\n",
        "            yield element\n",
        "\n",
        "        except Exception as e:\n",
        "\n",
        "            element['RATED_CURRENT'] =  0.0\n",
        "            yield element\n",
        "\n",
        "class DeriveRatedCOP(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        rated_capacity = element['RATED_CAPACITY']\n",
        "        rated_power = element['RATED_POWER']\n",
        "\n",
        "        if rated_capacity is not None and rated_power is not None and rated_power != 0:\n",
        "          element['RATED_COP'] = rated_capacity / rated_power\n",
        "        else:\n",
        "          element['RATED_COP'] = None\n",
        "\n",
        "        return [element]\n",
        "\n",
        "\n",
        "class ColumnCompressorFreqSpeed(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        compressor_rpm = element.get('VCC Compressor RPM')\n",
        "        power_supply_freq = element.get(' Power supply Freq')\n",
        "\n",
        "        # Check if {VCC Compressor RPM} is 'N/A'\n",
        "        if compressor_rpm == '' :\n",
        "            element['COMPRESSOR_FREQ_SPEED'] = power_supply_freq\n",
        "        else:\n",
        "            element['COMPRESSOR_FREQ_SPEED'] = compressor_rpm\n",
        "\n",
        "        return [element]\n",
        "\n",
        "\n",
        "class SetTypeToString(beam.DoFn):\n",
        "    def process(self, element):\n",
        "        element['CURR_A'] = str(element.get('CURR_A', ''))\n",
        "        return [element]\n",
        "\n",
        "\n",
        "def handle_nan(element):\n",
        "    import pandas as pd\n",
        "    for key, value in element.items():\n",
        "        if pd.isna(value) or pd.isnull(value):\n",
        "            element[key] = ''\n",
        "    return element\n",
        "\n",
        "\n",
        "class RemoveDecimalPoint(beam.DoFn):\n",
        "    def __init__(self, columns_to_remove):\n",
        "      self.columns_to_remove = columns_to_remove\n",
        "\n",
        "    def process(self, element):\n",
        "        for key in self.columns_to_remove:\n",
        "            if key in element and isinstance(element[key], float) and element[key].is_integer():\n",
        "                element[key] = str(int(element[key]))\n",
        "        yield element"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZpqXvq-Oxbz"
      },
      "source": [
        "##Runner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "y6fhiGwoOqt9",
        "outputId": "f618c726-96ab-4dcb-e3b2-b6d8bd0ee3cd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    div.alert {\n",
              "      white-space: pre-line;\n",
              "    }\n",
              "  </style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <link rel=\"stylesheet\" href=\"https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css\" integrity=\"sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh\" crossorigin=\"anonymous\">\n",
              "            <div class=\"alert alert-info\">No cache_root detected. Defaulting to staging_location gs://nidec-ga-temp/data-flow-pipelines/r&amp;d-product-selection-software/staging for cache location.</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#logging.getLogger().setLevel(logging.DEBUG)\n",
        "\n",
        "#pipeline_options = {\n",
        "#    'project':'nidec-ga'\n",
        "#}\n",
        "\n",
        "#\"\"\"\n",
        "pipeline_options = {\n",
        "    'project':'nidec-ga',\n",
        "    'runner':'DataflowRunner',\n",
        "    'region':'us-central1',\n",
        "    'staging_location':'gs://nidec-ga-temp/data-flow-pipelines/r&d-product-selection-software/staging',\n",
        "    'temp_location':'gs://nidec-ga-temp/data-flow-pipelines/r&d-product-selection-software/temp',\n",
        "    'template_location':'gs://nidec-ga-temp/data-flow-pipelines/r&d-product-selection-software/template/r&d-product-selection-software-curvecoefficient',\n",
        "    'requirements_file':'requirements.txt'\n",
        "}\n",
        "#\"\"\"\n",
        "\n",
        "pipeline_options = PipelineOptions.from_dictionary(pipeline_options)\n",
        "pipeline = beam.Pipeline(options=pipeline_options)\n",
        "\n",
        "def run_pipeline(temp_location, input_file_CDU_Curve_Coefficients, input_file_Envelope_Specification, input_file_CDU_Standard_Temperatures,  output_table):\n",
        "    import pandas as pd\n",
        "\n",
        "    cols_to_drop_performance = ['MODEL', 'CODE', 'STANDARD', 'MOTOR_TYPE', 'FLUID', 'VOLTAGE', 'FREQUENCY', 'CC_UNIT', 'CC0', 'CC1', 'CC2', 'CC3', 'CC4', 'CC5', 'CC6', 'CC7',\n",
        "    'CC8', 'CC9', 'CP0', 'CP1', 'CP2', 'CP3', 'CP4', 'CP5', 'CP6', 'CP7', 'CP8', 'CP9']\n",
        "\n",
        "    column_mapping_application = {\n",
        "        'Application': 'Test_application',\n",
        "    }\n",
        "\n",
        "    column_mapping_application_envelope = {\n",
        "        'Refrigerant': 'TEST_REFRIGERANT',\n",
        "        'ECO DESIGN DATASHEET': 'ECODESIGN',\n",
        "        'points': 'POINTS_OPERATION',\n",
        "        'Standard': 'STANDARD',\n",
        "        'out_ambient_min': 'OUT_AMBIENT_MIN',\n",
        "        'out_ambient_max': 'OUT_AMBIENT_MAX',\n",
        "        'out_evaporating_min': 'OUT_EVAPORATING_MIN',\n",
        "        'out_evaporating_max': 'OUT_EVAPORATING_MAX',\n",
        "        'PD_Config': 'PD_CONFIG',\n",
        "        'performance_curve_points': 'PERFORMANCE_CURVE_POINTS',\n",
        "    }\n",
        "\n",
        "    performance_replacements = [\n",
        "        ('CC_A', '#VALOR!', ''),('CC_A', '#REF!', ''),('CC_A', '#VALUE!', ''),('CC_A', '#HODNOTA!', ''),\n",
        "        ('CC_B', '#VALOR!', ''),('CC_B', '#REF!', ''),('CC_B', '#VALUE!', ''),('CC_B', '#HODNOTA!', ''),\n",
        "        ('CC_C', '#VALOR!', ''),('CC_C', '#REF!', ''),('CC_C', '#VALUE!', ''),('CC_C', '#HODNOTA!', ''),\n",
        "        ('CC_D', '#VALOR!', ''),('CC_D', '#REF!', ''),('CC_D', '#VALUE!', ''),('CC_D', '#HODNOTA!', ''),\n",
        "        ('CC_E', '#VALOR!', ''),('CC_E', '#REF!', ''),('CC_E', '#VALUE!', ''),('CC_E', '#HODNOTA!', ''),\n",
        "        ('CC_F', '#VALOR!', ''),('CC_F', '#REF!', ''),('CC_F', '#VALUE!', ''),('CC_F', '#HODNOTA!', ''),\n",
        "        ('CC_G', '#VALOR!', ''),('CC_G', '#REF!', ''),('CC_G', '#VALUE!', ''),('CC_G', '#HODNOTA!', ''),\n",
        "        ('CC_H', '#VALOR!', ''),('CC_H', '#REF!', ''),('CC_H', '#VALUE!', ''),('CC_H', '#HODNOTA!', ''),\n",
        "        ('CC_I', '#VALOR!', ''),('CC_I', '#REF!', ''),('CC_I', '#VALUE!', ''),('CC_I', '#HODNOTA!', ''),\n",
        "        ('CC_J', '#VALOR!', ''),('CC_J', '#REF!', ''),('CC_J', '#VALUE!', ''),('CC_J', '#HODNOTA!', ''),\n",
        "        ('CON_A', '#VALOR!', ''),('CON_A', '#REF!', ''),('CON_A', '#VALUE!', ''),('CON_A', '#HODNOTA!', ''),\n",
        "        ('CON_B', '#VALOR!', ''),('CON_B', '#REF!', ''),('CON_B', '#VALUE!', ''),('CON_B', '#HODNOTA!', ''),\n",
        "        ('CON_C', '#VALOR!', ''),('CON_C', '#REF!', ''),('CON_C', '#VALUE!', ''),('CON_C', '#HODNOTA!', ''),\n",
        "        ('CON_D', '#VALOR!', ''),('CON_D', '#REF!', ''),('CON_D', '#VALUE!', ''),('CON_D', '#HODNOTA!', ''),\n",
        "        ('CON_E', '#VALOR!', ''),('CON_E', '#REF!', ''),('CON_E', '#VALUE!', ''),('CON_E', '#HODNOTA!', ''),\n",
        "        ('CON_F', '#VALOR!', ''),('CON_F', '#REF!', ''),('CON_F', '#VALUE!', ''),('CON_F', '#HODNOTA!', ''),\n",
        "        ('CON_G', '#VALOR!', ''),('CON_G', '#REF!', ''),('CON_G', '#VALUE!', ''),('CON_G', '#HODNOTA!', ''),\n",
        "        ('CON_H', '#VALOR!', ''),('CON_H', '#REF!', ''),('CON_H', '#VALUE!', ''),('CON_H', '#HODNOTA!', ''),\n",
        "        ('CON_I', '#VALOR!', ''),('CON_I', '#REF!', ''),('CON_I', '#VALUE!', ''),('CON_I', '#HODNOTA!', ''),\n",
        "        ('CON_J', '#VALOR!', ''),('CON_J', '#REF!', ''),('CON_J', '#VALUE!', ''),('CON_J', '#HODNOTA!', ''),\n",
        "        ('CURR_A', '#VALOR!', ''),('CURR_A', '#REF!', ''),('CURR_A', '#VALUE!', ''),('CURR_A', '#HODNOTA!', ''),\n",
        "        ('CURR_B', '#VALOR!', ''),('CURR_B', '#REF!', ''),('CURR_B', '#VALUE!', ''),('CURR_B', '#HODNOTA!', ''),\n",
        "        ('CURR_C', '#VALOR!', ''),('CURR_C', '#REF!', ''),('CURR_C', '#VALUE!', ''),('CURR_C', '#HODNOTA!', ''),\n",
        "        ('CURR_D', '#VALOR!', ''),('CURR_D', '#REF!', ''),('CURR_D', '#VALUE!', ''),('CURR_D', '#HODNOTA!', ''),\n",
        "        ('CURR_E', '#VALOR!', ''),('CURR_E', '#REF!', ''),('CURR_E', '#VALUE!', ''),('CURR_E', '#HODNOTA!', ''),\n",
        "        ('CURR_F', '#VALOR!', ''),('CURR_F', '#REF!', ''),('CURR_F', '#VALUE!', ''),('CURR_F', '#HODNOTA!', ''),\n",
        "        ('CURR_G', '#VALOR!', ''),('CURR_G', '#REF!', ''),('CURR_G', '#VALUE!', ''),('CURR_G', '#HODNOTA!', ''),\n",
        "        ('CURR_H', '#VALOR!', ''),('CURR_H', '#REF!', ''),('CURR_H', '#VALUE!', ''),('CURR_H', '#HODNOTA!', ''),\n",
        "        ('CURR_I', '#VALOR!', ''),('CURR_I', '#REF!', ''),('CURR_I', '#VALUE!', ''),('CURR_I', '#HODNOTA!', ''),\n",
        "        ('CURR_J', '#VALOR!', ''),('CURR_J', '#REF!', ''),('CURR_J', '#VALUE!', ''),('CURR_J', '#HODNOTA!', ''),\n",
        "        ]\n",
        "\n",
        "    input_CDU_curve_coefficients_data = (\n",
        "        pipeline\n",
        "        | 'Performance Coefficients -- Create File Path Excel' >> beam.Create([input_file_CDU_Curve_Coefficients])\n",
        "        | 'Performance Coefficients -- Read Excel -> Origin' >> beam.FlatMap(lambda file:pd.read_csv(file, delimiter=',', engine='python').to_dict('records'))\n",
        "    )\n",
        "\n",
        "    grouped_clean_CDU_curve_coefficients_data = (\n",
        "        input_CDU_curve_coefficients_data\n",
        "        | \"handle NaN with ' '\" >> beam.ParDo(HandleNaN())\n",
        "        | \"new column derive Static\" >> beam.ParDo(UniqueValueForNewColum(new_column='COEFFICIENTS_TEMPERATURE_UNIT', value_column='C'))\n",
        "        | \"apply transformation in column Application\" >> beam.ParDo(TransformColumnApplication())\n",
        "        | \"rename column Application\" >> beam.ParDo(RenameColumns(column_mapping = column_mapping_application))\n",
        "        #| 'Count all elements 1' >> beam.combiners.Count.Globally()\n",
        "        #| beam.Map(print)\n",
        "    )\n",
        "\n",
        "\n",
        "    input_CDU_envelope_specification_data = (\n",
        "        pipeline\n",
        "        | 'Performance Envelope -- Create File Path Excel' >> beam.Create([input_file_Envelope_Specification])\n",
        "        | 'Performance Envelope -- Read Excel -> Origin' >> beam.FlatMap(lambda file:pd.read_csv(file, delimiter=',', engine='python').to_dict('records'))\n",
        "    )\n",
        "\n",
        "    grouped_CDU_curve_coefficients = (grouped_clean_CDU_curve_coefficients_data\n",
        "        | \"Grouped Business CurveCoefficients -- Standard Temperature -- Create Composite Key\" >> beam.ParDo(KeyByComposite(['Envelope']))\n",
        "        | 'Grouped Business CurveCoefficients -- Key StandTemp' >> beam.ParDo(CreateKeyDoFn(['Envelope']))\n",
        "    )\n",
        "\n",
        "    grouped_CDU_envelope_specification = (input_CDU_envelope_specification_data\n",
        "        | \"Grouped Business EnvelopeEspecification -- Standard Temperature -- Create Composite Key\" >> beam.ParDo(KeyByComposite(['envelope']))\n",
        "        | 'Grouped Business EnvelopeEspecification -- Key StandTemp' >> beam.ParDo(CreateKeyDoFn(['envelope']))\n",
        "    )\n",
        "\n",
        "    joined_data = ({'TABELA1':grouped_CDU_curve_coefficients, 'TABELA2':grouped_CDU_envelope_specification}\n",
        "        | \"CoGroupByKey\" >> beam.CoGroupByKey()\n",
        "        | 'Left Join' >> beam.ParDo(LeftJoinFn())\n",
        "    )\n",
        "\n",
        "    clean_CDU_envelope_coefficients_data = (\n",
        "        joined_data\n",
        "        | \"new column derive Coefficients\" >> beam.ParDo(UniqueValueForNewColum(new_column='COEFFICIENTS_OUTPUT_UNIT', value_column='W'))\n",
        "        | \"transform columns CCA~CCJ \"  >> beam.ParDo(CustomTransform())\n",
        "        | \"rename columns\" >> beam.ParDo(RenameColumns(column_mapping = column_mapping_application_envelope))\n",
        "        | \"drop selected columns\" >> beam.ParDo(DropColumnsTechnical(cols_to_drop = ['Envelope', 'PD_Config1', 'Exists in products']))\n",
        "        | \"convert in string ecodesign\" >> beam.ParDo(ColumnsToStringConverter(columns_to_string = ['ECODESIGN']))\n",
        "        | \"replacespaces CC_A~CURR_J\" >> beam.ParDo(ReplaceValues(replacements = performance_replacements))\n",
        "    )\n",
        "\n",
        "    grouped_CDU_envelope_coefficients = (clean_CDU_envelope_coefficients_data\n",
        "        | \"Grouped Business CurveEnvelopeCoefficients -- Standard Temperature -- Create Composite Key\" >> beam.ParDo(KeyByComposite(['STANDARD', 'Test_application', 'COEFFICIENTS_TEMPERATURE_UNIT']))\n",
        "        | 'Grouped Business CurveEnvelopeCoefficients -- Key StandTemp' >> beam.ParDo(CreateKeyDoFn(['STANDARD', 'Test_application', 'COEFFICIENTS_TEMPERATURE_UNIT']))\n",
        "    )\n",
        "\n",
        "\n",
        "    input_CDU_standard_temperatures_data = (\n",
        "        pipeline\n",
        "        | 'Standard Temperatures -- Create File Path Excel' >> beam.Create([input_file_CDU_Standard_Temperatures])\n",
        "        | 'Standard Temperatures -- Read Excel -> Origin' >> beam.FlatMap(lambda file:pd.read_csv(file, delimiter=',', engine='python').to_dict('records'))\n",
        "    )\n",
        "\n",
        "    grouped_CDU_standard_temperatures = (input_CDU_standard_temperatures_data\n",
        "        | \"Grouped Business Standard Temperatures -- Standard Temperature -- Create Composite Key\" >> beam.ParDo(KeyByComposite(['Standard', 'Application', 'T_coef_input']))\n",
        "        | 'Grouped Business Standard Temperatures -- Key StandTemp' >> beam.ParDo(CreateKeyDoFn(['Standard', 'Application', 'T_coef_input']))\n",
        "    )\n",
        "\n",
        "    joined_structured_data = ({'TABELA1':grouped_CDU_envelope_coefficients, 'TABELA2':grouped_CDU_standard_temperatures}\n",
        "        | \"CoGroupByKeyStructured\" >> beam.CoGroupByKey()\n",
        "        | 'Left JoinStructured' >> beam.ParDo(LeftJoinFn())\n",
        "    )\n",
        "\n",
        "\n",
        "    joined_business_data = (\n",
        "        joined_structured_data\n",
        "        #| \"drop TEST_APPLICATION column\" >> beam.ParDo(DropColumnsTechnical(cols_to_drop = ['TEST_APPLICATION']))\n",
        "        | \"convert in float\" >> beam.ParDo(ColumnsToFloatConverter(columns_to_float = ['CC_A', 'CON_A','Tevap','Treturn']))\n",
        "        | \"Derive Rated Capacity\" >> beam.ParDo(DeriveRatedCapacity())\n",
        "        | \"Derive Rated Power\" >> beam.ParDo(DeriveRatedPower())\n",
        "        | \"Derive Rated Current\" >> beam.ParDo(DeriveRatedCurrent())\n",
        "        | \"Derive Rated Cop\" >> beam.ParDo(DeriveRatedCOP())\n",
        "        | \"Column Compressor Freq Speed\" >> beam.ParDo(ColumnCompressorFreqSpeed())\n",
        "        | \"CURR_A to string\" >> beam.ParDo(SetTypeToString())\n",
        "        | \"drop selected columns POWER/VCC\" >> beam.ParDo(DropColumnsTechnical(cols_to_drop = [' Power supply Freq', 'VCC Compressor RPM']))\n",
        "        | \"rename columns joined data\" >> beam.ParDo(RenameColumns(column_mapping = {'Tevap': 'RATED_T_EVAP' , 'Tamb': 'RATED_T_AMB', 'Treturn': 'RATED_T_RETURN', 'SUB': 'RATED_T_SUB', 'SUP': 'RATED_T_SUP',\n",
        "          'Test_application': 'TEST_APPLICATION','Units': 'UNITS', 'Model': 'MODEL', 'Voltage1': 'VOLTAGE1', 'Freq1': 'FREQUENCY1',  'Voltage2': 'VOLTAGE2', 'Freq2': 'FREQUENCY2', 'Motor_type': 'MOTOR_TYPE'\n",
        "                                                       }))\n",
        "        | \"convert in integer\" >> beam.ParDo(ColumnsToIntegerConverter(columns_to_integer = ['FREQUENCY1', 'FREQUENCY2']))\n",
        "        | \"replacespatterns\" >> beam.ParDo(ReplaceValues(replacements = [('VOLTAGE1', ' ', ''),('VOLTAGE2', ' ', '')]))\n",
        "        | \"convert in integer Voltage2\" >> beam.ParDo(ColumnsToIntegerConverter(columns_to_integer = ['VOLTAGE2']))\n",
        "        | \"drop selected for match with schema\" >> beam.ParDo(DropColumnsTechnical(cols_to_drop = [ 'envelope', 'Standard', 'Application', 'T_coef_input', 'Test Application ']))\n",
        "        | \"handle NAN\" >> beam.Map(handle_nan)\n",
        "        | \"convert in float for match with schema\" >> beam.ParDo(ColumnsToFloatConverter(columns_to_float = ['CON_J', 'CON_I', 'CON_H', 'CON_G', 'CON_F', 'CON_E', 'CON_D', 'CON_C', 'CON_B', 'CURR_J', 'CURR_I', 'CURR_H',\n",
        "            'CURR_G', 'CURR_F', 'CURR_E', 'CURR_D', 'CURR_C', 'CURR_B', 'CURR_A']))\n",
        "        | \"convert in integer typing\" >> beam.ParDo(RemoveDecimalPoint(columns_to_remove = ['COMPRESSOR_FREQ_SPEED', 'RATED_T_SUP']))\n",
        "        #| 'ConvertToStringEcodesign' >> beam.ParDo(ConvertToStringEcodesign())\n",
        "        #| 'Count all elements' >> beam.combiners.Count.Globally()\n",
        "        #| beam.Map(print)\n",
        "        #| 'Type Analysis each columns' >> beam.ParDo(TypeAnalyzer())\n",
        "    )\n",
        "\n",
        "\n",
        "    joined_business_data | 'Write To BigQuery -> PSS DAD Trusted' >> beam.io.WriteToBigQuery(\n",
        "        table=output_table,\n",
        "        schema='SCHEMA_AUTODETECT',\n",
        "        create_disposition = beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
        "        write_disposition = beam.io.BigQueryDisposition.WRITE_TRUNCATE,\n",
        "        custom_gcs_temp_location = temp_location\n",
        "    )\n",
        "\n",
        "\n",
        "    #ib.show (joined_business_data)\n",
        "\n",
        "    pipeline.run().wait_until_finish()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    temp_location = 'gs://nidec-ga-temp/data-flow-pipelines/r&d-product-selection-software/temp'\n",
        "\n",
        "    input_file_CDU_Curve_Coefficients = 'gs://nidec-ga-transient/r&d-product-selection-software/cdu/CDU PSS Database - Curve Coefficients.csv'\n",
        "\n",
        "    input_file_Envelope_Specification = 'gs://nidec-ga-transient/r&d-product-selection-software/cdu/CDU PSS Database - Envelope Specification.csv'\n",
        "\n",
        "    input_file_CDU_Standard_Temperatures = 'gs://nidec-ga-transient/r&d-product-selection-software/cdu/CDU PSS Database - StandardTemp.csv'\n",
        "\n",
        "    output_table = 'nidec-ga:bq_trusted.PSS_CURVE_COEFFICIENTS_CDU'\n",
        "\n",
        "    run_pipeline(temp_location, input_file_CDU_Curve_Coefficients, input_file_Envelope_Specification, input_file_CDU_Standard_Temperatures,  output_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fSyrE6g8rGp2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}